{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimized DecisionTree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KorKanticha/SeniorProject/blob/main/Optimized_DecisionTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optimized DecisionTree"
      ],
      "metadata": {
        "id": "Q0bhhyrhX0eU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Base Model\n"
      ],
      "metadata": {
        "id": "YXuCQlRgX_mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3z-91udYEwg",
        "outputId": "9ea189f2-c8e5-4093-e9cd-404c133219bf"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xls_Suicide = pd.ExcelFile(\"/content/gdrive/MyDrive/SeniorProject_KorBoss/Dummy_data3.xlsx\")\n",
        "df = dict()\n",
        "df = pd.read_excel(xls_Suicide)"
      ],
      "metadata": {
        "id": "9VHXF5r0gqil"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split dataset in features and target variable\n",
        "list_col = list(df.columns)\n",
        "feature_cols = list(list_col)\n",
        "feature_cols.remove(\"Success\")\n",
        "feature_cols.remove(\"Province_Happen_ไม่ทราบ\")\n",
        "feature_cols.remove(\"Province_Happen_99\")\n",
        "feature_cols.remove(\"Province_Happen_ \")"
      ],
      "metadata": {
        "id": "iywXYsFNhc1L"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = df[feature_cols] # Features\n",
        "y = df.Success # Target variable\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "micro_precision = precision_score(y_pred, y_test, average='micro')\n",
        "print('Micro-averaged precision score: {0:0.2f}'.format(\n",
        "      micro_precision))\n",
        "\n",
        "macro_precision = precision_score(y_pred, y_test, average='macro')\n",
        "print('Macro-averaged precision score: {0:0.2f}'.format(\n",
        "      macro_precision))\n",
        "\n",
        "per_class_precision = precision_score(y_pred, y_test, average=None)\n",
        "print('Per-class precision score:', per_class_precision)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6xKLhMcqYjyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd3753f-9cdf-4360-b4fc-bcc7e577c5e4"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9554319415588768\n",
            "Micro-averaged precision score: 0.96\n",
            "Macro-averaged precision score: 0.95\n",
            "Per-class precision score: [0.96347607 0.93737769]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aXIF_LsEK37",
        "outputId": "3627d22f-3f26-4f1c-ca60-3f4984873cac"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9945,  377],\n",
              "       [ 288, 4311]])"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co343VyvE0AH",
        "outputId": "7970551e-5505-4e6c-b0bd-0560b3788c1a"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97     10322\n",
            "           1       0.92      0.94      0.93      4599\n",
            "\n",
            "    accuracy                           0.96     14921\n",
            "   macro avg       0.95      0.95      0.95     14921\n",
            "weighted avg       0.96      0.96      0.96     14921\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optimize Model"
      ],
      "metadata": {
        "id": "YiFZUL5FYBx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 - Import the library - GridSearchCv\n",
        "Here we have imported various modules like decomposition, datasets, tree, Pipeline, StandardScaler and GridSearchCV from differnt libraries. We will understand the use of these later while using it in the in the code snipet.\n",
        "For now just have a look on these imports."
      ],
      "metadata": {
        "id": "lPllRdqkGDEc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "id": "u3mtx-GCXxn8"
      },
      "outputs": [],
      "source": [
        "from sklearn import decomposition, datasets\n",
        "from sklearn import tree\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 - Setup the Data\n",
        "Here we have used datasets to load the inbuilt wine dataset and we have created objects X and y to store the data and the target value respectively."
      ],
      "metadata": {
        "id": "8GgBrHzMGV77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = datasets.load_wine()\n",
        "#X = dataset.data\n",
        "#y = dataset.target"
      ],
      "metadata": {
        "id": "BV-VjU9-GWeC"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 - Using StandardScaler and PCA\n",
        "StandardScaler is used to remove the outliners and scale the data by making the mean of the data 0 and standard deviation as 1. So we are creating an object std_scl to use standardScaler.\n"
      ],
      "metadata": {
        "id": "awMm7czHGZaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "std_slc = StandardScaler()\n",
        "pca = decomposition.PCA()\n",
        "dec_tree = tree.DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "8GUzt1sSGgDF"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 - Using Pipeline for GridSearchCV\n",
        "Pipeline will helps us by passing modules one by one through GridSearchCV for which we want to get the best parameters. So we are making an object pipe to create a pipeline for all the three objects std_scl, pca and dec_tree."
      ],
      "metadata": {
        "id": "2AU5IIoFGmjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
        "                           ('pca', pca),\n",
        "                           ('dec_tree', dec_tree)])\n",
        "n_components = list(range(1,X.shape[1]+1,1))\n",
        "criterion = ['gini', 'entropy']\n",
        "max_depth = [2,4,6,8,10,12]\n",
        "parameters = dict(pca__n_components=n_components,\n",
        "                      dec_tree__criterion=criterion,\n",
        "                      dec_tree__max_depth=max_depth)"
      ],
      "metadata": {
        "id": "LydmFrK1GmGg"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 - Using GridSearchCV and Printing Results"
      ],
      "metadata": {
        "id": "a1pS-htmGz5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_GS = GridSearchCV(pipe, parameters)\n",
        "clf_GS.fit(X, y)\n",
        "print('Best Criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
        "print('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
        "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
        "print(); print(clf_GS.best_estimator_.get_params()['dec_tree'])\n"
      ],
      "metadata": {
        "id": "H3UbmsqUG1Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4)\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "micro_precision = precision_score(y_pred, y_test, average='micro')\n",
        "print('Micro-averaged precision score: {0:0.2f}'.format(\n",
        "      micro_precision))\n",
        "\n",
        "macro_precision = precision_score(y_pred, y_test, average='macro')\n",
        "print('Macro-averaged precision score: {0:0.2f}'.format(\n",
        "      macro_precision))\n",
        "\n",
        "per_class_precision = precision_score(y_pred, y_test, average=None)\n",
        "print('Per-class precision score:', per_class_precision)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFxiDN7tM7iH",
        "outputId": "7d00c528-7564-403b-a574-2c1925db1e99"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.923530594464178\n",
            "Micro-averaged precision score: 0.92\n",
            "Macro-averaged precision score: 0.92\n",
            "Per-class precision score: [0.92288316 0.92498369]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.94     10322\n",
            "           1       0.84      0.92      0.88      4599\n",
            "\n",
            "    accuracy                           0.92     14921\n",
            "   macro avg       0.90      0.92      0.91     14921\n",
            "weighted avg       0.93      0.92      0.92     14921\n",
            "\n"
          ]
        }
      ]
    }
  ]
}